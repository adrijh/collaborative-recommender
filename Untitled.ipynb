{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv(\"data/movies.csv\")\n",
    "ratings = pd.read_csv(\"data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100836, 4)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we are working with a reduced version of a dataset, we can see that movieId and userId does not match our indexes (there are skipped movies and users). This is not very convenient so let's change that. We are gonna create a transformation dictionary and apply it to both the movie and user dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.userId = ratings.userId.astype('category').cat.codes.values\n",
    "ratings.movieId = ratings.movieId.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>609</td>\n",
       "      <td>9416</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>609</td>\n",
       "      <td>9443</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>609</td>\n",
       "      <td>9444</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>609</td>\n",
       "      <td>9445</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>609</td>\n",
       "      <td>9485</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            0        0     4.0   964982703\n",
       "1            0        2     4.0   964981247\n",
       "2            0        5     4.0   964982224\n",
       "3            0       43     5.0   964983815\n",
       "4            0       46     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     609     9416     4.0  1493848402\n",
       "100832     609     9443     5.0  1493850091\n",
       "100833     609     9444     5.0  1494273047\n",
       "100834     609     9445     5.0  1493846352\n",
       "100835     609     9485     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Based Recommender - Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create our utility matrix, where each row is an user instance and each column a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.pivot_table(data=ratings,values='rating',index='userId', columns='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9714</th>\n",
       "      <th>9715</th>\n",
       "      <th>9716</th>\n",
       "      <th>9717</th>\n",
       "      <th>9718</th>\n",
       "      <th>9719</th>\n",
       "      <th>9720</th>\n",
       "      <th>9721</th>\n",
       "      <th>9722</th>\n",
       "      <th>9723</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "userId                                                               ...   \n",
       "0         4.0   NaN   4.0   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...   \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "605       2.5   NaN   NaN   NaN   NaN   NaN   2.5   NaN   NaN   NaN  ...   \n",
       "606       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "607       2.5   2.0   2.0   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...   \n",
       "608       3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...   \n",
       "609       5.0   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "movieId  9714  9715  9716  9717  9718  9719  9720  9721  9722  9723  \n",
       "userId                                                               \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "605       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "606       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "607       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "608       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "609       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, our ratings go from X to . So in order to help solve a future cold start problem, it is convenient to perform mean normalization to the matrix. We will use scikit-learn for convenience, but it can be done manually with ease. NOTE WE END UP USING STANDARD SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# df_std = std_scaler.fit_transform(df)\n",
    "# df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objetive is for our recommender to learn a set of features for the movies (x0,x1,..,xk) and a set of weights for each user (theta0,...,thetak) that represents their preference for each of the features x each movie has.  For a certain user i the dot product x(i,k)*theta(i) should give us a the predicted rating r(i,k) our user would assign to movie k.\n",
    "\n",
    "Therefore for all users and movies our problem can be translated to finding two matrices X,Theta containing the movie features and user preferences such that X*Theta=R with R our user-rating matrix. This is called Matrix Factorization and how we approach it will greatly impact the scalability and speed of our Recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by splitting the training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's initialize our matrices randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "n = R.shape[0]\n",
    "m = R.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a list of the indices for the pairs user-rating that are non-null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items = (~np.isnan(R)*1).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow us to create a training and test set were we have eliminated certain ratings from the training set so that we can test our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.3\n",
    "test_size= int(n*test_percent)\n",
    "test_index = np.random.randint(low=0, high=users.shape[0],size=test_size, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50460,  84914,  94452,  10226,  68983,  11941,  75179,  99743,\n",
       "         7221,  98638,  65201,  42629,  61223,  98387,  41480,  99855,\n",
       "        55920,   1048,  80742,  16098,  86048,  19232,  39606,  84657,\n",
       "        33738,   2911,   9778,  30111,  94582,  70869,  28183, 100715,\n",
       "        45100,  75780,  27403,   5383,  24982,  83807,  73322,  62449,\n",
       "        92085,  13443,  47297,  50824,  47513,  81178,  49950,  98989,\n",
       "        57136,  22935,  39897,  64328,  25031,  59045,  45692,  71434,\n",
       "         1480,  87204,  88331,  76178,  24178,   4138,  94283,  64466,\n",
       "        51171,  11168,  96478,  39376,  53693,  95044,  18895,  73224,\n",
       "        25886,   8352,  85447,  45287,   2864,  14212,   8331,  79775,\n",
       "        18613,   6515,  98538,  98777,  38997,  74081,  67858,  91237,\n",
       "        81870,  10881,  87075,  12175,  50880,  27070,  87114,  39922,\n",
       "        41207,  95443,  86521,  17898,  16700,   2794,  14253,  24208,\n",
       "          525,  43612,   9220,  30830,  16125,   5941,  53165,  50049,\n",
       "         6883,   1119,  47516,  58246,  64938,  27711,  37279,  19473,\n",
       "        92308,  21871,  41083,  86331,  37221,   3957,  66932,  24571,\n",
       "        59573,   9117,   4671,  30572,  30334,  67834,  32587,   4226,\n",
       "        34922,  69763,  85573,   2286,   5593,  90742,  97515,  18103,\n",
       "        57505,  19480,  29674,  81403,  43767,  12275,   3482,  82989,\n",
       "        84747,  51189,  45097,  74062,  73832,  18838,  59906,  13488,\n",
       "        46355,  53542,  32760,  68831,  92307,  72113,  43946,  32693,\n",
       "        68907,  84402,  32032,  54978,  93282,  15561,  83772,  32444,\n",
       "        28937,  67959,   1130,  74659,  52128,  59775,  37725])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R[users[0],items[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = np.copy(R)\n",
    "for r_index in test_index:\n",
    "    R_train[users[r_index],items[r_index]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.rand(n,k)\n",
    "M = np.random.rand(m,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U Matrix: (610, 20)\n",
      "M Matrix: (9724, 20)\n"
     ]
    }
   ],
   "source": [
    "print('U Matrix: {}'.format(U.shape))\n",
    "print('M Matrix: {}'.format(M.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "l=0.001\n",
    "n_epoch = 50\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    for user in range(R_train.shape[0]):\n",
    "        item_index = (~np.isnan(R_train[user,:])*1).nonzero()[0]\n",
    "        for movie in item_index:\n",
    "            err = R_train[user,movie] - np.dot(U[user],M[movie])\n",
    "            U[user] = U[user] + lr*(err*M[movie]-l*U[user])\n",
    "            M[movie] = M[movie] + lr*(err*U[user]-l*M[movie])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = U @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the error on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8880269396656362"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se=0\n",
    "for r_index in test_index: \n",
    "    se = se + (R[users[r_index],items[r_index]]  - R_pred[users[r_index],items[r_index]])**2\n",
    "    \n",
    "mse=se/test_size\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885918455719154"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 4.0  Predicted: 3.7\n",
      "Original: 4.0  Predicted: 4.4\n",
      "Original: 2.0  Predicted: 2.8\n",
      "Original: 3.5  Predicted: 3.6\n",
      "Original: 2.0  Predicted: 1.8\n",
      "Original: 5.0  Predicted: 3.8\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 5.0  Predicted: 4.3\n",
      "Original: 3.0  Predicted: 2.8\n",
      "Original: 2.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 3.5  Predicted: 3.5\n",
      "Original: 3.0  Predicted: 4.0\n",
      "Original: 4.0  Predicted: 3.4\n",
      "Original: 5.0  Predicted: 4.5\n",
      "Original: 5.0  Predicted: 4.1\n",
      "Original: 3.5  Predicted: 3.2\n",
      "Original: 3.0  Predicted: 3.4\n",
      "Original: 3.5  Predicted: 3.3\n",
      "Original: 2.5  Predicted: 2.9\n",
      "Original: 3.0  Predicted: 2.8\n",
      "Original: 4.0  Predicted: 3.1\n",
      "Original: 3.0  Predicted: 3.1\n",
      "Original: 2.0  Predicted: 4.2\n",
      "Original: 3.0  Predicted: 3.2\n",
      "Original: 3.0  Predicted: 2.7\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 2.0  Predicted: 3.5\n",
      "Original: 3.5  Predicted: 2.7\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 3.0  Predicted: 3.5\n",
      "Original: 2.5  Predicted: 3.4\n",
      "Original: 2.5  Predicted: 2.6\n",
      "Original: 4.0  Predicted: 3.6\n",
      "Original: 4.0  Predicted: 4.2\n",
      "Original: 3.0  Predicted: 3.6\n",
      "Original: 5.0  Predicted: 3.3\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 3.0  Predicted: 3.7\n",
      "Original: 2.5  Predicted: 3.3\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 3.0  Predicted: 3.6\n",
      "Original: 4.0  Predicted: 2.8\n",
      "Original: 0.5  Predicted: 2.8\n",
      "Original: 2.0  Predicted: 1.9\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 2.5  Predicted: 2.9\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 2.5  Predicted: 3.5\n",
      "Original: 3.5  Predicted: 3.1\n",
      "Original: 5.0  Predicted: 3.8\n",
      "Original: 3.5  Predicted: 3.2\n",
      "Original: 5.0  Predicted: 3.9\n",
      "Original: 2.0  Predicted: 4.6\n",
      "Original: 5.0  Predicted: 3.7\n",
      "Original: 5.0  Predicted: 3.3\n",
      "Original: 4.0  Predicted: 3.3\n",
      "Original: 4.0  Predicted: 3.4\n",
      "Original: 3.0  Predicted: 3.8\n",
      "Original: 4.5  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 2.9\n",
      "Original: 4.0  Predicted: 3.2\n",
      "Original: 3.0  Predicted: 2.9\n",
      "Original: 4.0  Predicted: 4.3\n",
      "Original: 2.5  Predicted: 3.1\n",
      "Original: 4.0  Predicted: 3.1\n",
      "Original: 2.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 4.3\n",
      "Original: 3.0  Predicted: 3.8\n",
      "Original: 5.0  Predicted: 5.0\n",
      "Original: 3.5  Predicted: 3.2\n",
      "Original: 3.0  Predicted: 3.0\n",
      "Original: 5.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 4.2\n",
      "Original: 2.5  Predicted: 2.5\n",
      "Original: 1.0  Predicted: 2.7\n",
      "Original: 3.0  Predicted: 3.2\n",
      "Original: 5.0  Predicted: 4.0\n",
      "Original: 4.0  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 3.9\n",
      "Original: 3.0  Predicted: 4.7\n",
      "Original: 0.5  Predicted: 2.0\n",
      "Original: 2.0  Predicted: 4.2\n",
      "Original: 3.5  Predicted: 2.9\n",
      "Original: 4.0  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 1.0  Predicted: 2.9\n",
      "Original: 3.0  Predicted: 2.9\n",
      "Original: 3.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 2.0  Predicted: 2.8\n",
      "Original: 5.0  Predicted: 3.7\n",
      "Original: 3.0  Predicted: 4.4\n",
      "Original: 3.0  Predicted: 3.1\n",
      "Original: 3.0  Predicted: 4.0\n",
      "Original: 3.5  Predicted: 2.7\n",
      "Original: 3.5  Predicted: 3.6\n",
      "Original: 2.5  Predicted: 3.9\n",
      "Original: 4.5  Predicted: 5.0\n",
      "Original: 2.0  Predicted: 2.0\n",
      "Original: 3.5  Predicted: 3.2\n",
      "Original: 4.5  Predicted: 4.1\n",
      "Original: 3.0  Predicted: 2.9\n",
      "Original: 3.0  Predicted: 3.7\n",
      "Original: 4.0  Predicted: 4.2\n",
      "Original: 3.0  Predicted: 3.4\n",
      "Original: 4.0  Predicted: 3.4\n",
      "Original: 3.0  Predicted: 3.8\n",
      "Original: 4.0  Predicted: 3.4\n",
      "Original: 3.5  Predicted: 2.8\n",
      "Original: 4.0  Predicted: 2.9\n",
      "Original: 1.0  Predicted: 4.0\n",
      "Original: 2.0  Predicted: 2.8\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 4.5  Predicted: 3.4\n",
      "Original: 4.5  Predicted: 4.1\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 4.0  Predicted: 3.0\n",
      "Original: 4.0  Predicted: 4.4\n",
      "Original: 3.0  Predicted: 3.8\n",
      "Original: 4.0  Predicted: 3.3\n",
      "Original: 3.0  Predicted: 3.3\n",
      "Original: 3.5  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 3.7\n",
      "Original: 4.5  Predicted: 3.9\n",
      "Original: 4.0  Predicted: 3.2\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 2.5  Predicted: 2.7\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 2.5  Predicted: 2.7\n",
      "Original: 4.5  Predicted: 4.2\n",
      "Original: 1.0  Predicted: 2.4\n",
      "Original: 2.0  Predicted: 2.9\n",
      "Original: 4.0  Predicted: 2.5\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 3.0  Predicted: 3.0\n",
      "Original: 4.0  Predicted: 3.9\n",
      "Original: 2.0  Predicted: 2.0\n",
      "Original: 4.0  Predicted: 3.8\n",
      "Original: 5.0  Predicted: 4.1\n",
      "Original: 5.0  Predicted: 4.1\n",
      "Original: 4.0  Predicted: 4.2\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 2.0  Predicted: 3.6\n",
      "Original: 3.0  Predicted: 3.1\n",
      "Original: 2.0  Predicted: 2.8\n",
      "Original: 3.5  Predicted: 3.3\n",
      "Original: 3.5  Predicted: 3.2\n",
      "Original: 4.0  Predicted: 2.8\n",
      "Original: 4.0  Predicted: 4.0\n",
      "Original: 2.5  Predicted: 1.8\n",
      "Original: 2.5  Predicted: 3.6\n",
      "Original: 4.0  Predicted: 3.5\n",
      "Original: 5.0  Predicted: 4.7\n",
      "Original: 2.5  Predicted: 3.3\n",
      "Original: 3.5  Predicted: 3.9\n",
      "Original: 3.0  Predicted: 3.9\n",
      "Original: 2.0  Predicted: 3.2\n",
      "Original: 3.0  Predicted: 3.0\n",
      "Original: 4.0  Predicted: 3.1\n",
      "Original: 5.0  Predicted: 5.2\n",
      "Original: 5.0  Predicted: 4.1\n",
      "Original: 2.0  Predicted: 3.1\n",
      "Original: 3.0  Predicted: 3.5\n",
      "Original: 4.0  Predicted: 2.1\n",
      "Original: 3.0  Predicted: 4.1\n",
      "Original: 2.0  Predicted: 3.1\n",
      "Original: 2.0  Predicted: 3.1\n",
      "Original: 3.0  Predicted: 2.5\n",
      "Original: 4.0  Predicted: 3.6\n",
      "Original: 4.5  Predicted: 3.1\n",
      "Original: 3.0  Predicted: 3.8\n",
      "Original: 3.5  Predicted: 3.1\n",
      "Original: 3.5  Predicted: 3.3\n",
      "Original: 0.5  Predicted: 3.6\n",
      "Original: 3.0  Predicted: 3.9\n",
      "Original: 4.5  Predicted: 4.3\n",
      "Original: 2.5  Predicted: 2.8\n",
      "Original: 3.0  Predicted: 2.5\n"
     ]
    }
   ],
   "source": [
    "for index in test_index:    \n",
    "    print('Original: {}'.format(R[users[index],items[index]]) + '  ' + 'Predicted: {:.1f}'.format(R_pred[users[index],items[index]]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('U_matrix', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('M_matrix', M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Bias Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First in order to simplify our code, let's create a few functions to automate every step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,y,i,j):\n",
    "        return mu + bi[i] + bj[j] + np.dot(x[i],y[j])\n",
    "        \n",
    "           \n",
    "def init_matrix(rmatrix,k):\n",
    "        n = rmatrix.shape[0]\n",
    "        m = rmatrix.shape[1]\n",
    "        U = np.random.rand(n,k)\n",
    "        M = np.random.rand(m,k)\n",
    "        return U,M,n,m\n",
    "\n",
    "def sgd_step(rmatrix,x,y,i,j):\n",
    "        err = rmatrix[i,j] - predict(x,y,i,j)\n",
    "        x[i] = x[i] + lr*(err*y[j]-l*x[i])\n",
    "        y[j] = y[j] + lr*(err*x[i]-l*y[j])\n",
    "            \n",
    "        \n",
    "def train(rmatrix,x,y,n_epoch,mu,bi,bj):\n",
    "        for epoch in range(n_epoch):\n",
    "            for user in range(rmatrix.shape[0]):\n",
    "                item_index = (~np.isnan(rmatrix[user,:])*1).nonzero()[0]\n",
    "                for movie in item_index:\n",
    "                    sgd_step(rmatrix,x,y,user,movie,mu,bi,bj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve our predictions, we will add bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,y,i,j,mu,bi,bj):\n",
    "        return mu + bi[i] + bj[j] + np.dot(x[i],y[j])\n",
    "\n",
    "def sgd_step(rmatrix,x,y,i,j,mu,bi,bj):\n",
    "        err = rmatrix[i,j] - predict(x,y,i,j,mu,bi,bj)\n",
    "        x[i] += lr*(err*y[j]-l*x[i])\n",
    "        y[j] += lr*(err*x[i]-l*y[j])\n",
    "        bi[i] += lr*(err - l*bi[i])\n",
    "        bj[j] += lr*(err - l*bj[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "l=0.001\n",
    "n_epoch = 50\n",
    "k = 20\n",
    "\n",
    "U,M,n,m = init_matrix(R,k)\n",
    "\n",
    "mu = np.mean(R_train[~np.isnan(R_train)])\n",
    "bi = np.random.rand(n)\n",
    "bj = np.random.rand(m)\n",
    "\n",
    "train(R_train,U,M,n_epoch,mu,bi,bj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred = ((mu + U @ M.T)+bj)+bi[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807428285195072"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se=0\n",
    "for r_index in test_index: \n",
    "    se = se + (R[users[r_index],items[r_index]]  - R_pred[users[r_index],items[r_index]])**2\n",
    "    \n",
    "mse=se/test_size\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757079299885421"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great results! Now let's wrap it in scikit-learn-like object so we can work with ease and effectively perform a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MatrixFactorizer():\n",
    "    \n",
    "    def __init__(self, n_latent = 15, n_epoch = 30, learning_rate = 0.001,\n",
    "                 lmbda = 0.001, test_percent=0.3,random_state=None):\n",
    "        \n",
    "        self.k = n_latent\n",
    "        self.n_epoch = n_epoch\n",
    "        self.lr = learning_rate\n",
    "        self.l = lmbda\n",
    "        self.test_percent = test_percent\n",
    "        self.random_state = random_state\n",
    "\n",
    "    \n",
    "    def predict(self,U,M,i,j,mu,bi,bj):\n",
    "            return mu + bi[i] + bj[j] + np.dot(U[i],M[j])\n",
    "        \n",
    "    def sgd_step(self,R,U,M,i,j,mu,bi,bj):\n",
    "        lr = self.lr\n",
    "        l = self.l\n",
    "        err = R[i,j] - self.predict(self.U,self.M,i,j,self.mu,self.bi,self.bj)\n",
    "        self.U[i] += lr*(err*self.M[j]-l*self.U[i])\n",
    "        self.M[j] += lr*(err*self.U[i]-l*self.M[j])\n",
    "        self.bi[i] += lr*(err - l*self.bi[i])\n",
    "        self.bj[j] += lr*(err - l*self.bj[j])\n",
    "    \n",
    "    def init_params(self,R):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.n = R.shape[0]\n",
    "        self.m = R.shape[1]\n",
    "        self.U = np.random.rand(self.n,self.k)\n",
    "        self.M = np.random.rand(self.m,self.k)\n",
    "        \n",
    "    def init_intercept(self,R):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.mu = np.mean(R[~np.isnan(R)])\n",
    "        self.bi = np.random.rand(self.n)\n",
    "        self.bj = np.random.rand(self.m)\n",
    "        \n",
    "\n",
    "    def fit(self, R):\n",
    "        \n",
    "        self.present_epoch = 0\n",
    "        self.init_params(R)\n",
    "        self.init_intercept(R)\n",
    "         \n",
    "        \n",
    "        for epoch in range(self.n_epoch):\n",
    "            self.present_epoch += 1\n",
    "            self.partial_fit(R)\n",
    "            print('Trained epoch ({}/{})'.format(self.present_epoch,self.n_epoch))\n",
    "            \n",
    "        \n",
    "        \n",
    "    def partial_fit(self, R):\n",
    "        \n",
    "        for user in range(self.n):\n",
    "                item_index = (~np.isnan(R[user,:])*1).nonzero()[0]\n",
    "                for movie in item_index:\n",
    "                    self.sgd_step(R,self.U,self.M,user,movie,self.mu,self.bi,self.bj)\n",
    "    \n",
    "    \n",
    "    def transform(self):\n",
    "        return ((self.mu + self.U @ (self.M).T)+self.bj)+self.bi[:, None]\n",
    "    \n",
    "    def fit_transform(self,R):\n",
    "        self.fit(R)\n",
    "        return self.transform()\n",
    "    \n",
    "    def score(self,R,R_pred,test_index):\n",
    "        \n",
    "        users,items = (~np.isnan(R)*1).nonzero()\n",
    "        test_size = test_index.shape[0]\n",
    "        se=0\n",
    "        \n",
    "        for r_index in test_index: \n",
    "            se += (R[users[r_index],items[r_index]]  - R_pred[users[r_index],items[r_index]])**2\n",
    "    \n",
    "        mse=se/test_size\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_mf(R, test_percent=0.3,random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    n = R.shape[0]\n",
    "    ## We obtain the information about the non-null data in our ranking matrix\n",
    "    users,items = (~np.isnan(R)*1).nonzero()\n",
    "        \n",
    "    ## Create a random subset corresponding to our test data\n",
    "    test_size= int(n*test_percent)\n",
    "    test_index = np.random.randint(low=0, high=users.shape[0],size=test_size, dtype=int)\n",
    "        \n",
    "    ## We create our training set removing the test rankings\n",
    "    R_train = np.copy(R)\n",
    "    for r_index in test_index:\n",
    "        R_train[users[r_index],items[r_index]] = np.nan\n",
    "            \n",
    "    return R_train, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9149867160110354, 0.8372006904766592)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train, test_index = train_test_mf(R,random_state=42)\n",
    "mf = MatrixFactorizer(n_latent=15,n_epoch=100,learning_rate=0.001,random_state=42)\n",
    "R_pred = mf.fit_transform(R_train)\n",
    "mf.score(R,R_pred,test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study how our model error changes in each epoch for our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "R_train, test_index = train_test_mf(R,random_state=42)\n",
    "mf = MatrixFactorizer(n_latent=15,random_state=42)\n",
    "mf.init_params(R_train)\n",
    "mf.init_intercept(R_train)\n",
    "test_error = []\n",
    "for epoch in range(n_epoch):\n",
    "    mf.partial_fit(R_train)\n",
    "    R_pred = mf.transform()\n",
    "    test_rmse, test_mse = mf.score(R,R_pred,test_index)\n",
    "    test_error.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(n_epoch),test_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(n_epoch)[20:],test_error[20:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our error starts increasing at around 60 epochs, most likely due to SGD overfitting our data. From now on we will assume this number of epochs as a standard to fit our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that both the user and movie matrix (U,M) are unknowns, we are dealing wit a non-convex problem. Because of this it is quite likely for the gradient descent to get stuck in a local minimum. An appropiate learning rate schedule may help us improve the recommender's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t,lr0,lrinf,alpha=0.05):\n",
    "    c2 = lrinf\n",
    "    c1 = lr0 - c2\n",
    "        \n",
    "    return (c1*np.exp(-t*alpha))+c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "R_train, test_index = train_test_mf(R,random_state=42)\n",
    "mf = MatrixFactorizer(n_latent=15,random_state=42)\n",
    "mf.init_params(R_train)\n",
    "mf.init_intercept(R_train)\n",
    "for epoch in range(n_epoch):\n",
    "    mf.lr = learning_schedule(epoch,0.01,0.0001,alpha=0.05)\n",
    "    mf.partial_fit(R_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9898606562886413, 0.9798241188681795)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred = mf.transform()\n",
    "mf.score(R,R_pred,test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our learning rate schedule significantly improves our model convergence. Now we will perform a grid search to find a good set of hyperparameter values for k and lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda_l = [0.1,0.01,0.001]\n",
    "k_l = [10,20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmbda: 0.1 | latent_feat: 10 | mse: 0.7783482564046749\n",
      "lmbda: 0.1 | latent_feat: 20 | mse: 0.7716603974685764\n",
      "lmbda: 0.1 | latent_feat: 30 | mse: 0.7297751174207412\n",
      "lmbda: 0.01 | latent_feat: 10 | mse: 0.8262736324843788\n",
      "lmbda: 0.01 | latent_feat: 20 | mse: 0.8744961024893396\n",
      "lmbda: 0.01 | latent_feat: 30 | mse: 0.7839383800218369\n",
      "lmbda: 0.001 | latent_feat: 10 | mse: 0.8339329732513667\n",
      "lmbda: 0.001 | latent_feat: 20 | mse: 0.8969852371266412\n",
      "lmbda: 0.001 | latent_feat: 30 | mse: 0.7973619656667493\n"
     ]
    }
   ],
   "source": [
    "for lmbda in lmbda_l:\n",
    "    for k in k_l:\n",
    "        R_train, test_index = train_test_mf(R,random_state=42)\n",
    "        mf = MatrixFactorizer(n_latent=k,n_epoch=60,learning_rate=0.001,lmbda=lmbda,random_state=42)\n",
    "        R_pred = mf.fit_transform(R_train)\n",
    "        rmse, mse = mf.score(R,R_pred,test_index)\n",
    "        print('lmbda: {}'.format(lmbda) + ' | ' + 'latent_feat: {}'.format(k) + ' | ' + 'mse: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems Lambda = 0.1 and 30 latent features gives the best results. Note thas these values are at the ends of our samples, so it may be worthwhile trying more values around them. For now we will keep these. For sanity check, let's make sure our results are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85426876181957, 0.7297751174207412)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train, test_index = train_test_mf(R,random_state=42)\n",
    "mf = MatrixFactorizer(n_latent=30,n_epoch=60,learning_rate=0.001,random_state=42,lmbda=0.1)\n",
    "R_pred = mf.fit_transform(R_train)\n",
    "mf.score(R,R_pred,test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 1M DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1m = pd.read_csv('data/ratings1m.dat',sep='::',header=None,names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1m.drop('timestamp', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1m.userId = ratings1m.userId.astype('category').cat.codes.values\n",
    "ratings1m.movieId = ratings1m.movieId.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = pd.pivot_table(data=ratings1m,values='rating',index='userId', columns='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3696</th>\n",
       "      <th>3697</th>\n",
       "      <th>3698</th>\n",
       "      <th>3699</th>\n",
       "      <th>3700</th>\n",
       "      <th>3701</th>\n",
       "      <th>3702</th>\n",
       "      <th>3703</th>\n",
       "      <th>3704</th>\n",
       "      <th>3705</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "userId                                                               ...   \n",
       "0         5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "6035      NaN   NaN   NaN   2.0   NaN   3.0   NaN   NaN   NaN   NaN  ...   \n",
       "6036      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "6037      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "6038      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "6039      3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "movieId  3696  3697  3698  3699  3700  3701  3702  3703  3704  3705  \n",
       "userId                                                               \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6035      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6036      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6037      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6038      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6039      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[6040 rows x 3706 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2= np.array(R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how our model performs in this dataset. (It will take a lot more time to fit than the 100k dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch (1/60)\n",
      "Trained epoch (2/60)\n",
      "Trained epoch (3/60)\n",
      "Trained epoch (4/60)\n",
      "Trained epoch (5/60)\n",
      "Trained epoch (6/60)\n",
      "Trained epoch (7/60)\n",
      "Trained epoch (8/60)\n",
      "Trained epoch (9/60)\n",
      "Trained epoch (10/60)\n",
      "Trained epoch (11/60)\n",
      "Trained epoch (12/60)\n",
      "Trained epoch (13/60)\n",
      "Trained epoch (14/60)\n",
      "Trained epoch (15/60)\n",
      "Trained epoch (16/60)\n",
      "Trained epoch (17/60)\n",
      "Trained epoch (18/60)\n",
      "Trained epoch (19/60)\n",
      "Trained epoch (20/60)\n",
      "Trained epoch (21/60)\n",
      "Trained epoch (22/60)\n",
      "Trained epoch (23/60)\n",
      "Trained epoch (24/60)\n",
      "Trained epoch (25/60)\n",
      "Trained epoch (26/60)\n",
      "Trained epoch (27/60)\n",
      "Trained epoch (28/60)\n",
      "Trained epoch (29/60)\n",
      "Trained epoch (30/60)\n",
      "Trained epoch (31/60)\n",
      "Trained epoch (32/60)\n",
      "Trained epoch (33/60)\n",
      "Trained epoch (34/60)\n",
      "Trained epoch (35/60)\n",
      "Trained epoch (36/60)\n",
      "Trained epoch (37/60)\n",
      "Trained epoch (38/60)\n",
      "Trained epoch (39/60)\n",
      "Trained epoch (40/60)\n",
      "Trained epoch (41/60)\n",
      "Trained epoch (42/60)\n",
      "Trained epoch (43/60)\n",
      "Trained epoch (44/60)\n",
      "Trained epoch (45/60)\n",
      "Trained epoch (46/60)\n",
      "Trained epoch (47/60)\n",
      "Trained epoch (48/60)\n",
      "Trained epoch (49/60)\n",
      "Trained epoch (50/60)\n",
      "Trained epoch (51/60)\n",
      "Trained epoch (52/60)\n",
      "Trained epoch (53/60)\n",
      "Trained epoch (54/60)\n",
      "Trained epoch (55/60)\n",
      "Trained epoch (56/60)\n",
      "Trained epoch (57/60)\n",
      "Trained epoch (58/60)\n",
      "Trained epoch (59/60)\n",
      "Trained epoch (60/60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9106858736854151, 0.8293487605301678)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train, test_index = train_test_mf(R2,random_state=42)\n",
    "mf = MatrixFactorizer(n_latent=30,n_epoch=60,learning_rate=0.001,lmbda=0.1,random_state=42)\n",
    "R_pred = mf.fit_transform(R_train)\n",
    "mf.score(R2,R_pred,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
